- [2 OLMo 2 Furious](https://arxiv.org/pdf/2501.00656)
- [1.58-bit FLUX](https://www.arxiv.org/pdf/2412.18653)
- [Memory Layers at Scale](https://arxiv.org/pdf/2412.09764)
- [Agents Are Not Enough](https://arxiv.org/html/2412.16241v1)
- [Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like LLMs](https://arxiv.org/pdf/2412.21187)
- [IsarStep: a Benchmark for High-level Mathematical Reasoning](https://arxiv.org/pdf/2006.09265)
- [DRT-o1: Optimized Deep Reasoning Translation via Long Chain-of-Thought](https://arxiv.org/pdf/2412.17498)
- [LearnLM: Improving Gemini for Learning](https://www.arxiv.org/pdf/2412.16429)
- [DeepSeek-V3 Technical Report](https://arxiv.org/pdf/2412.19437)
- [Large Concept Models: Language Modeling in a Sentence Representation Space](https://arxiv.org/pdf/2412.08821)
- [Explore Theory of Mind: Program-guided adversarial data generation for theory of mind reasoning](https://arxiv.org/pdf/2412.12175)
- [Reinforcement Learning: An Overview](https://arxiv.org/pdf/2412.05265)
- [GENESIS: Generative Scene Inference and Sampling with Object-Centric Latent Representations](https://arxiv.org/pdf/1907.13052)
- [AutoFeedback: An LLM-based Framework for Efficient and Accurate API Request Generation](https://arxiv.org/pdf/2410.06943)
- [TheAgentCompany: Benchmarking LLM Agents on Consequential Real World Tasks](https://arxiv.org/pdf/2412.14161)
- [Alignment faking in large language models](https://arxiv.org/pdf/2412.14093)
- [Qwen2.5 Technical Report](https://arxiv.org/pdf/2412.15115)
- [Precise Length Control in Large Language Models](https://arxiv.org/pdf/2412.11937)
- [MAG-V: A Multi-Agent Framework for Synthetic Data Generation and Verification](https://arxiv.org/pdf/2412.04494)
- [AutoReason: Automatic Few-Shot Reasoning Decomposition](https://arxiv.org/pdf/2412.06975)
- [Does RLHF Scale? Exploring the Impacts from Data, Model, and Method](https://arxiv.org/html/2412.06000#:~:text=As%20a%20result%2C%20current%20RLHF,for%20reinforcement%20learning%20of%20LLMs.)
- [Phi-4 Technical Report](https://arxiv.org/html/2412.08905v1)
- [Byte Latent Transformer: Patches Scale Better Than Tokens](https://arxiv.org/pdf/2412.09871)
- [A Survey on LLM-as-a-Judge](https://arxiv.org/pdf/2411.15594)
- [Nvidia launches new AI development tools for autonomous robots and vehicles](https://cur.at/xmbDGsT?m=web)

-------------



- [FaceXBench: Evaluating Multimodal LLMs on Face Understanding](http://arxiv.org/abs/2501.10360)
- [DexForce: Extracting Force-informed Actions from Kinesthetic Demonstrations for Dexterous Manipulation](http://arxiv.org/abs/2501.10356)
- [ColNet: Collaborative Optimization in Decentralized Federated Multi-task Learning Systems](http://arxiv.org/abs/2501.10347)
- [3rd Workshop on Maritime Computer Vision (MaCVi) 2025: Challenge Results](http://arxiv.org/abs/2501.10343)
- [MVTamperBench: Evaluating Robustness of Vision-Language Models](http://arxiv.org/abs/2412.19794)
- [Agent4Edu: Generating Learner Response Data by Generative Agents for Intelligent Education Systems](http://arxiv.org/abs/2501.10332)
- [Large language models for automated scholarly paper review: A survey](http://arxiv.org/abs/2501.10326)
- [DiffStereo: High-Frequency Aware Diffusion Model for Stereo Image Restoration](http://arxiv.org/abs/2501.10325)
- [New Fashion Products Performance Forecasting: A Survey on Evolutions, Models and Emerging Trends](http://arxiv.org/abs/2501.10324)
- [Hierarchical Autoregressive Transformers: Combining Byte-~and Word-Level Processing for Robust, Adaptable Language Models](http://arxiv.org/abs/2501.10322)
- [Towards Human-Guided, Data-Centric LLM Co-Pilots](http://arxiv.org/abs/2501.10321)
- [Natural Language Processing of Privacy Policies: A Survey](http://arxiv.org/abs/2501.10319)
- [HiMix: Reducing Computational Complexity in Large Vision-Language Models](http://arxiv.org/abs/2501.10318)
- [Two Types of AI Existential Risk: Decisive and Accumulative](http://arxiv.org/abs/2401.07836)
- [Computational Protein Science in the Era of Large Language Models (LLMs)](http://arxiv.org/abs/2501.10282)
- [MutualForce: Mutual-Aware Enhancement for 4D Radar-LiDAR 3D Object Detection](http://arxiv.org/abs/2501.10266)
- [Towards Large Reasoning Models: A Survey on Scaling LLM Reasoning Capabilities](http://arxiv.org/abs/2501.09686)
- [Large Language Model is Secretly a Protein Sequence Optimizer](http://arxiv.org/abs/2501.09274)
- [The Animal-AI Environment: A Virtual Laboratory For Comparative Cognition and Artificial Intelligence Research](http://arxiv.org/abs/2312.11414)
- [Exploring the Impact of Generative Artificial Intelligence in Education: A Thematic Analysis](http://arxiv.org/abs/2501.10134)
-----------------
- [Video-RAG: Visually-aligned Retrieval-Augmented Long Video Comprehension](https://arxiv.org/pdf/2411.13093)
- [MiniMax-01: Scaling Foundation Models with Lightning Attention](https://arxiv.org/pdf/2501.08313)
- [LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs](https://arxiv.org/pdf/2406.15319)
- [Transformer2: Self-adaptive LLMs](https://arxiv.org/html/2501.06252v2)
- [Foundations of Large Language Models](https://arxiv.org/pdf/2501.09223)
